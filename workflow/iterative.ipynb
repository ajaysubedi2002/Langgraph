{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0118a79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph,START, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c869a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = ChatGoogleGenerativeAI(model='models/gemini-2.5-flash-lite')\n",
    "optimizer_llm = ChatGoogleGenerativeAI(model='models/gemini-2.5-flash-lite')\n",
    "evaluator_llm = ChatGoogleGenerativeAI(model='models/gemini-2.5-flash-lite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde8dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
    "    feedback: str = Field(..., description=\"feedback for the tweet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fbe6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_evaluator_llm  = evaluator_llm.with_structured_output(TweetEvaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b056662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class TweetState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int\n",
    "\n",
    "    tweet_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1164117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_tweet(state: TweetState):\n",
    "\n",
    "    # prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "\n",
    "        Rules:\n",
    "        - Do NOT use question-answer format.\n",
    "        - Max 280 characters.\n",
    "        - Use observational humor, irony, sarcasm, or cultural references.\n",
    "        - Think in meme logic, punchlines, or relatable takes.\n",
    "        - Use simple, day to day english\n",
    "        \"\"\")\n",
    "        ]\n",
    "\n",
    "    # send generator_llm\n",
    "    response = generator_llm.invoke(messages).content\n",
    "\n",
    "    # return response\n",
    "    return {'tweet': response, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36389b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tweet(state: TweetState):\n",
    "\n",
    "    # prompt\n",
    "    messages = [\n",
    "    SystemMessage(content=\"You are a ruthless, no-laugh-given Twitter critic. You evaluate tweets based on humor, originality, virality, and tweet format.\"),\n",
    "    HumanMessage(content=f\"\"\"\n",
    "Evaluate the following tweet:\n",
    "\n",
    "Tweet: \"{state['tweet']}\"\n",
    "\n",
    "Use the criteria below to evaluate the tweet:\n",
    "\n",
    "1. Originality ‚Äì Is this fresh, or have you seen it a hundred times before?  \n",
    "2. Humor ‚Äì Did it genuinely make you smile, laugh, or chuckle?  \n",
    "3. Punchiness ‚Äì Is it short, sharp, and scroll-stopping?  \n",
    "4. Virality Potential ‚Äì Would people retweet or share it?  \n",
    "5. Format ‚Äì Is it a well-formed tweet (not a setup-punchline joke, not a Q&A joke, and under 280 characters)?\n",
    "\n",
    "Auto-reject if:\n",
    "- It's written in question-answer format (e.g., \"Why did...\" or \"What happens when...\")\n",
    "- It exceeds 280 characters\n",
    "- It reads like a traditional setup-punchline joke\n",
    "- Dont end with generic, throwaway, or deflating lines that weaken the humor (e.g., ‚ÄúMasterpieces of the auntie-uncle universe‚Äù or vague summaries)\n",
    "\n",
    "### Respond ONLY in structured format:\n",
    "- evaluation: \"approved\" or \"needs_improvement\"  \n",
    "- feedback: One paragraph explaining the strengths and weaknesses \n",
    "\"\"\")\n",
    "]\n",
    "\n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "\n",
    "    return {'evaluation':response.evaluation, 'feedback': response.feedback, 'feedback_history': [response.feedback]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752866f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_tweet(state: TweetState):\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality and humor based on given feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Improve the tweet based on this feedback:\n",
    "\"{state['feedback']}\"\n",
    "\n",
    "Topic: \"{state['topic']}\"\n",
    "Original Tweet:\n",
    "{state['tweet']}\n",
    "\n",
    "Re-write it as a short, viral-worthy tweet. Avoid Q&A style and stay under 280 characters.\n",
    "\"\"\")\n",
    "    ]\n",
    "\n",
    "    response = optimizer_llm.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "\n",
    "    return {'tweet': response, 'iteration': iteration, 'tweet_history': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a44add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_evaluation(state: TweetState):\n",
    "\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd75a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = StateGraph(TweetState)\n",
    "\n",
    "graph.add_node('generate', generate_tweet)\n",
    "graph.add_node('evaluate', evaluate_tweet)\n",
    "graph.add_node('optimize', optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "\n",
    "graph.add_conditional_edges('evaluate', route_evaluation, {'approved': END, 'needs_improvement': 'optimize'})\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3585c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"topic\": \"Nepal politican \",\n",
    "    \"iteration\": 1,\n",
    "    \"max_iteration\": 5\n",
    "}\n",
    "result = workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dd5af48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Nepal politican ',\n",
       " 'tweet': 'Just saw a Nepalese politician giving a speech. Pretty sure he accidentally nominated himself for \"Most Dramatic Pause\" at the next international conference. The mountain goats were more excited. üêêüòÇ #NepalPolitics #SpeechGoals',\n",
       " 'evaluation': 'approved',\n",
       " 'feedback': \"The tweet is original, humorous, and uses a relatable comparison to mountain goats to emphasize the dramatic pause. Its length and use of hashtags make it suitable for Twitter's format, and it has good potential for virality due to its lighthearted critique and humor. The tweet successfully avoids common pitfalls like question-answer formats or setup-punchline structures.\",\n",
       " 'iteration': 1,\n",
       " 'max_iteration': 5,\n",
       " 'tweet_history': ['Just saw a Nepalese politician giving a speech. Pretty sure he accidentally nominated himself for \"Most Dramatic Pause\" at the next international conference. The mountain goats were more excited. üêêüòÇ #NepalPolitics #SpeechGoals'],\n",
       " 'feedback_history': [\"The tweet is original, humorous, and uses a relatable comparison to mountain goats to emphasize the dramatic pause. Its length and use of hashtags make it suitable for Twitter's format, and it has good potential for virality due to its lighthearted critique and humor. The tweet successfully avoids common pitfalls like question-answer formats or setup-punchline structures.\"]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8552cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My brain trying to pronounce \"srhberhb\" vs. my brain trying to remember where I left my keys. One is a cosmic mystery, the other is apparently a lost civilization. #srhberhb #brainfog #sendhelp\n"
     ]
    }
   ],
   "source": [
    "for tweet in result['tweet_history']:\n",
    "    print(tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
